{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão de avaliação dos sentimentos positivos/negativos\n",
    "\n",
    "**Estratégia utilizada - TF-IDF**\n",
    "\n",
    " **O que é TF-IDF?**\n",
    "\n",
    "> \"O valor tf–idf, é uma medida estatística que tem o intuito de indicar\n",
    "> a importância de uma palavra de um documento em relação a uma coleção\n",
    "> de documentos ou em um corpus linguístico\"\n",
    "> \n",
    "> \"O valor tf–idf de uma palavra aumenta proporcionalmente à medida que\n",
    "> aumenta o número de ocorrências dela em um documento, no entanto, esse\n",
    "> valor é equilibrado pela frequência da palavra no corpus.\"\n",
    "> [Wikipedia](https://pt.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "\n",
    "TF - Frequência do termo, o numero de vezes que uma palavra aparece num determinado texto/documento. Porém esse número somente não é o suficiente para tirar uma conclusão absoluta, pois existem palavras que aparecem muito sem ter tanto peso, como a palavra \"uma\", \"um\".\n",
    "\n",
    "IDF - Inverso da Frequência do Termo, diminui o peso das palavras que aparecem demais e aumenta das que aparecem menos.\n",
    "\n",
    "![Processamento de texto usando TD-IDF](https://cdn-images-1.medium.com/max/1200/1*_OsV8gO2cjy9qcFhrtCdiw.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Processamento dos dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo os dados\n",
    "amazon = pd.read_table('amazon_cells_labelled.txt', names=['frase','sentimento'])\n",
    "imdb = pd.read_table('imdb_labelled.txt', names=['frase','sentimento'])\n",
    "yelp = pd.read_table('yelp_labelled.txt', names=['frase','sentimento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               frase  sentimento\n",
       "0  So there is no way for me to plug it in here i...           0\n",
       "1                        Good case, Excellent value.           1\n",
       "2                             Great for the jawbone.           1\n",
       "3  Tied to charger for conversations lasting more...           0\n",
       "4                                  The mic is great.           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop word e pontuações** - Stop word são palavras vazias, que não agregam ao modelo de IA e que podem ser retiradas, assim como as pontuações, iremos vetorizar as palavras num bow(bag of words) e não precisamos delas, então irei retira-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pros(mess):\n",
    "    \n",
    "    #Retira pontuação\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "    \n",
    "    #Junta tudo em uma lista novamente\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    #Tira stopwords\n",
    "    mess = [word for word in nopunc.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    return mess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [So, way, plug, US, unless, I, go, converter]\n",
       "1                       [Good, case, Excellent, value]\n",
       "2                                     [Great, jawbone]\n",
       "3    [Tied, charger, conversations, lasting, 45, mi...\n",
       "4                                    [The, mic, great]\n",
       "Name: frase, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon['frase'].head(5).apply(text_pros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o bow de palavras como no head acima\n",
    "#\"Fitamos\" e depois transformamos ele num bag of words\n",
    "bow_frases = CountVectorizer(analyzer=text_pros).fit(amazon['frase'])\n",
    "bow_frases = bow_frases.transform(amazon['frase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez com o bow, precisamos ter o \"peso correto\" das palavras, de acordo com sua incidência, então precisamos transforma-las novamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mais uma vez precisamos \"fitar\" e transformar nossos dados\n",
    "tfidf_frases = TfidfTransformer().fit(bow_frases)\n",
    "tfidf_frases = tfidf_frases.transform(bow_frases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Machine Learning\n",
    "\n",
    "Agora com os dados já no formato de TF-IDF podemos submete-los a um modelo de Inteligencia Artificial, o classificador escolhido foi o Naive Bayes, ou Teorema de Bayes que:\n",
    "\n",
    "> \"descreve a probabilidade de um evento, baseado em um conhecimento a\n",
    "> priori que pode estar relacionado ao evento\"\n",
    "> [Wikipedia](https://pt.wikipedia.org/wiki/Teorema_de_Bayes)\n",
    "\n",
    "Mas poderia ser outro, como um Random Forest por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Fitando\" o modelo.\n",
    "sentimento_detect = MultinomialNB().fit(tfidf_frases, amazon['sentimento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tirando as primeiras previsões do modelo\n",
    "all_predictions = sentimento_detect.predict(tfidf_frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       500\n",
      "           1       0.96      0.99      0.97       500\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(amazon['sentimento'], all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repetindo todo o processo para os dados do Imdb e Yelp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/.local/lib/python2.7/site-packages/ipykernel_launcher.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "bow_frases_imdb = CountVectorizer(analyzer=text_pros).fit(imdb['frase'])\n",
    "bow_frases_imdb = bow_frases_imdb.transform(imdb['frase'])\n",
    "tfidf_frases_imbd = TfidfTransformer().fit(bow_frases_imdb)\n",
    "tfidf_frases_imbd = tfidf_frases_imbd.transform(bow_frases_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimento_detect_imdb = MultinomialNB().fit(tfidf_frases_imbd, imdb['sentimento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_imdb = sentimento_detect_imdb.predict(tfidf_frases_imbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       362\n",
      "           1       0.98      0.98      0.98       386\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       748\n",
      "   macro avg       0.98      0.98      0.98       748\n",
      "weighted avg       0.98      0.98      0.98       748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(imdb['sentimento'], all_predictions_imdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/.local/lib/python2.7/site-packages/ipykernel_launcher.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "bow_frases_yelp = CountVectorizer(analyzer=text_pros).fit(yelp['frase'])\n",
    "bow_frases_yelp = bow_frases_yelp.transform(yelp['frase'])\n",
    "tfidf_frases_yelp = TfidfTransformer().fit(bow_frases_yelp)\n",
    "tfidf_frases_yelp = tfidf_frases_yelp.transform(bow_frases_yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimento_detect_yelp = MultinomialNB().fit(tfidf_frases_yelp, yelp['sentimento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_yelp = sentimento_detect_yelp.predict(tfidf_frases_yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       500\n",
      "           1       0.97      0.95      0.96       500\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1000\n",
      "   macro avg       0.96      0.96      0.96      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(yelp['sentimento'], all_predictions_yelp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações finais\n",
    "\n",
    "**Possíveis melhoras**\n",
    "\n",
    " - Tenho ciencia que o bom desempenho dos algoritmos se da ao fato de\n",
    "   que eles foram testados com os mesmos dados do que foram treinados.\n",
    "   Tentei dividir os dados antes de treinar os modelos, porém me\n",
    "   confundi em alguns momentos e acabava caindo em erros de tipo de\n",
    "   dados e reshape.\n",
    " - Uso do Pipeline, com processamento de dados um pouco mais complexo\n",
    "   como esse, o uso do Pipeline do  Sklearn pode ajudar bastante na\n",
    "   \"automação\" dessas tratativas com os dados. Não utilizei por receio\n",
    "   de treinar o modelo imdb com dados da amazon e vice-versa, em algum\n",
    "   momento algum dado de um data frame \"invadir\" o outro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
